atlasza-doc-vetter/
  app.py
  vetter/
    __init__.py
    config.py
    extract.py
    llm.py
    schemas.py
    rules.py
    report.py
    pipeline.py
  rules/
    za_default.yaml
  requirements.txt
  .env.example
  .gitignore
  README.md
streamlit==1.37.1
pydantic==2.8.2
python-dotenv==1.0.1
PyYAML==6.0.2
pypdf==4.3.1
requests==2.32.3
reportlab==4.2.2
# Choose one:
LLM_PROVIDER=openai
# LLM_PROVIDER=anthropic
# LLM_PROVIDER=custom

# If using OpenAI-compatible APIs:
LLM_API_KEY=put_your_key_here
LLM_BASE_URL=https://api.openai.com/v1
LLM_MODEL=gpt-4o-mini

# Behavior
REDACT_BEFORE_SENDING=true
MAX_CHARS_PER_DOC=18000
jurisdiction: "South Africa"
default_decision: "NEEDS_REVIEW"

doc_types:
  - KYC_COMPANY
  - KYB_COMPANY
  - AML_DECLARATION
  - SALES_CONTRACT
  - EXPORT_PERMIT
  - OTHER

required_by_type:
  KYC_COMPANY:
    - company_name
    - registration_number
    - registered_address
    - director_or_authorised_signatory
    - signature_present

  KYB_COMPANY:
    - company_name
    - registration_number
    - directors_list_or_reference
    - ubo_declaration_or_reference

  AML_DECLARATION:
    - company_name
    - declaration_present
    - signature_present
    - date

  SALES_CONTRACT:
    - buyer
    - seller
    - commodity
    - quantity
    - price_or_pricing_mechanism
    - incoterms_or_delivery_terms
    - contract_date
    - signature_present

  EXPORT_PERMIT:
    - issuing_authority_or_reference
    - permit_number
    - commodity
    - validity_dates_or_issue_date
    - exporter_name

cross_doc_checks:
  - name: "Company name consistency"
    field: company_name
  - name: "Registration number consistency"
    field: registration_number
import os
import uuid
import streamlit as st
from vetter.config import load_settings
from vetter.pipeline import run_vetting

st.set_page_config(page_title="AtlasZA Document Vetter", layout="wide")

settings = load_settings()

st.title("AtlasZA – KYC/KYB/AML + Commodities Document Vetter")
st.caption("Runs locally. Hybrid mode: local extraction + optional external AI for classification/extraction.")

with st.expander("Settings (read-only)", expanded=False):
    st.write({
        "LLM_PROVIDER": settings.llm_provider,
        "LLM_MODEL": settings.llm_model,
        "REDACT_BEFORE_SENDING": settings.redact_before_sending,
        "MAX_CHARS_PER_DOC": settings.max_chars_per_doc
    })

uploaded = st.file_uploader(
    "Upload PDF documents",
    type=["pdf"],
    accept_multiple_files=True
)

run_btn = st.button("Run Vetting", type="primary", disabled=not uploaded)

if run_btn:
    os.makedirs("uploads", exist_ok=True)
    os.makedirs("outputs", exist_ok=True)

    batch_id = str(uuid.uuid4())[:8]
    batch_dir = os.path.join("uploads", batch_id)
    os.makedirs(batch_dir, exist_ok=True)

    paths = []
    for f in uploaded:
        path = os.path.join(batch_dir, f.name)
        with open(path, "wb") as out:
            out.write(f.getbuffer())
        paths.append(path)

    with st.spinner("Extracting, classifying, checking rules, generating PDF report..."):
        result = run_vetting(paths, rules_path="rules/za_default.yaml", settings=settings)

    st.subheader("Outcome")
    st.success(f"Decision: {result.decision}")
    st.write(result.summary)

    st.subheader("Flags / Findings")
    if result.findings:
        for item in result.findings:
            st.warning(item)
    else:
        st.write("No findings.")

    st.subheader("Per-document results")
    for doc in result.documents:
        with st.expander(f"{doc.filename} — {doc.doc_type} — {doc.decision}", expanded=False):
            st.write("Missing fields:", doc.missing_fields or "None")
            st.write("Extracted fields:")
            st.json(doc.fields)

    st.subheader("PDF Report")
    st.write("Download the generated report:")
    with open(result.report_path, "rb") as f:
        st.download_button(
            label="Download PDF report",
            data=f,
            file_name=os.path.basename(result.report_path),
            mime="application/pdf"
        )
from dataclasses import dataclass
import os
from dotenv import load_dotenv

@dataclass
class Settings:
    llm_provider: str
    llm_api_key: str
    llm_base_url: str
    llm_model: str
    redact_before_sending: bool
    max_chars_per_doc: int

def load_settings() -> Settings:
    load_dotenv()
    return Settings(
        llm_provider=os.getenv("LLM_PROVIDER", "openai").strip(),
        llm_api_key=os.getenv("LLM_API_KEY", "").strip(),
        llm_base_url=os.getenv("LLM_BASE_URL", "https://api.openai.com/v1").strip(),
        llm_model=os.getenv("LLM_MODEL", "gpt-4o-mini").strip(),
        redact_before_sending=os.getenv("REDACT_BEFORE_SENDING", "true").lower() == "true",
        max_chars_per_doc=int(os.getenv("MAX_CHARS_PER_DOC", "18000")),
    )
from pypdf import PdfReader

def extract_pdf_text(path: str, max_chars: int) -> str:
    reader = PdfReader(path)
    parts = []
    for page in reader.pages:
        t = page.extract_text() or ""
        if t.strip():
            parts.append(t)
        if sum(len(p) for p in parts) > max_chars:
            break
    text = "\n\n".join(parts)
    return text[:max_chars]
from pypdf import PdfReader

def extract_pdf_text(path: str, max_chars: int) -> str:
    reader = PdfReader(path)
    parts = []
    for page in reader.pages:
        t = page.extract_text() or ""
        if t.strip():
            parts.append(t)
        if sum(len(p) for p in parts) > max_chars:
            break
    text = "\n\n".join(parts)
    return text[:max_chars]
import json
import requests

class LLMError(Exception):
    pass

def chat_json(base_url: str, api_key: str, model: str, system: str, user: str) -> dict:
    if not api_key:
        raise LLMError("Missing LLM_API_KEY. Put it in a .env file.")

    url = base_url.rstrip("/") + "/chat/completions"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }
    payload = {
        "model": model,
        "messages": [
            {"role": "system", "content": system},
            {"role": "user", "content": user},
        ],
        "temperature": 0.0,
        "response_format": {"type": "json_object"},
    }

    r = requests.post(url, headers=headers, data=json.dumps(payload), timeout=60)
    if r.status_code >= 400:
        raise LLMError(f"LLM HTTP {r.status_code}: {r.text[:4000]}")

    data = r.json()
    try:
        content = data["choices"][0]["message"]["content"]
        return json.loads(content)
    except Exception as e:
        raise LLMError(f"Bad LLM response format: {e}")
from pydantic import BaseModel, Field
from typing import Any, Dict, List, Optional

class DocResult(BaseModel):
    filename: str
    doc_type: str
    fields: Dict[str, Any] = Field(default_factory=dict)
    missing_fields: List[str] = Field(default_factory=list)
    decision: str = "NEEDS_REVIEW"

class BatchResult(BaseModel):
    decision: str
    summary: str
    findings: List[str]
    documents: List[DocResult]
    report_path: str
import yaml
from typing import Dict, List, Any, Tuple

def load_rules(path: str) -> dict:
    with open(path, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)

def required_fields_for(doc_type: str, rules: dict) -> List[str]:
    return rules.get("required_by_type", {}).get(doc_type, [])

def cross_doc_checks(rules: dict) -> List[dict]:
    return rules.get("cross_doc_checks", [])
import os
from reportlab.lib.pagesizes import A4
from reportlab.pdfgen import canvas

def render_pdf(report_path: str, decision: str, summary: str, findings: list, docs: list):
    os.makedirs(os.path.dirname(report_path), exist_ok=True)
    c = canvas.Canvas(report_path, pagesize=A4)
    width, height = A4

    y = height - 60
    c.setFont("Helvetica-Bold", 16)
    c.drawString(50, y, "AtlasZA Document Vetting Report")
    y -= 30

    c.setFont("Helvetica", 11)
    c.drawString(50, y, f"Decision: {decision}")
    y -= 20
    c.drawString(50, y, f"Summary: {summary[:140]}")
    y -= 30

    c.setFont("Helvetica-Bold", 12)
    c.drawString(50, y, "Findings:")
    y -= 18
    c.setFont("Helvetica", 10)
    if findings:
        for f in findings[:30]:
            c.drawString(60, y, f"- {f[:120]}")
            y -= 14
            if y < 80:
                c.showPage()
                y = height - 60
    else:
        c.drawString(60, y, "- None")
        y -= 14

    c.setFont("Helvetica-Bold", 12)
    c.drawString(50, y, "Documents:")
    y -= 18
    c.setFont("Helvetica", 10)

    for d in docs:
        line = f"{d.filename} | {d.doc_type} | {d.decision}"
        c.drawString(60, y, line[:120])
        y -= 14
        if d.missing_fields:
            c.drawString(70, y, f"Missing: {', '.join(d.missing_fields)[:110]}")
            y -= 14
        if y < 80:
            c.showPage()
            y = height - 60

    c.save()
import os
import re
from typing import List, Dict, Any

from vetter.extract import extract_pdf_text
from vetter.llm import chat_json, LLMError
from vetter.rules import load_rules, required_fields_for, cross_doc_checks
from vetter.schemas import DocResult, BatchResult
from vetter.report import render_pdf

REDACT_PATTERNS = [
    # very lightweight redaction MVP (improve later)
    (re.compile(r"\b\d{13}\b"), "[REDACTED_ID_NUMBER]"),  # SA ID-like
    (re.compile(r"\b[A-Z0-9._%+-]+@[A-Z0-9.-]+\.[A-Z]{2,}\b", re.I), "[REDACTED_EMAIL]"),
    (re.compile(r"\b\d{2,4}[- ]?\d{3,4}[- ]?\d{3,4}\b"), "[REDACTED_POSSIBLE_ACCOUNT_OR_PHONE]"),
]

SYSTEM = """You are a compliance document analysis assistant.
You will:
1) classify the document type
2) extract fields into a JSON object
Return ONLY valid JSON.

Doc types allowed:
KYC_COMPANY, KYB_COMPANY, AML_DECLARATION, SALES_CONTRACT, EXPORT_PERMIT, OTHER

Guidelines:
- If unsure, choose OTHER.
- Only extract what is explicitly supported by text.
- Use null for unknown values.
"""

def redact(text: str) -> str:
    out = text
    for pat, rep in REDACT_PATTERNS:
        out = pat.sub(rep, out)
    return out

def llm_classify_and_extract(text: str, filename: str, rules: dict, settings) -> Dict[str, Any]:
    required_keys = [
        "company_name", "registration_number", "registered_address",
        "director_or_authorised_signatory", "directors_list_or_reference", "ubo_declaration_or_reference",
        "declaration_present", "signature_present", "date",
        "buyer", "seller", "commodity", "quantity", "price_or_pricing_mechanism",
        "incoterms_or_delivery_terms", "contract_date",
        "issuing_authority_or_reference", "permit_number", "validity_dates_or_issue_date", "exporter_name"
    ]

    user = f"""
Filename: {filename}

Document text:
\"\"\"{text}\"\"\"

Return JSON with:
- doc_type
- fields: object containing any relevant keys from this list: {required_keys}
- notes: short string
"""

    data = chat_json(
        base_url=settings.llm_base_url,
        api_key=settings.llm_api_key,
        model=settings.llm_model,
        system=SYSTEM,
        user=user
    )
    # minimal normalization
    doc_type = (data.get("doc_type") or "OTHER").strip().upper()
    fields = data.get("fields") or {}
    if not isinstance(fields, dict):
        fields = {}
    return {"doc_type": doc_type, "fields": fields, "notes": data.get("notes", "")}

def apply_rules(doc_type: str, fields: dict, rules: dict) -> List[str]:
    missing = []
    for req in required_fields_for(doc_type, rules):
        v = fields.get(req)
        if v is None or (isinstance(v, str) and not v.strip()) is True:
            missing.append(req)
        if v is False:  # explicit false fails requirement like signature_present
            missing.append(req)
    # de-dup
    return sorted(list(set(missing)))

def apply_cross_doc_checks(docs: List[DocResult], rules: dict) -> List[str]:
    findings = []
    checks = cross_doc_checks(rules)
    for chk in checks:
        field = chk.get("field")
        name = chk.get("name", field)
        values = []
        for d in docs:
            v = d.fields.get(field)
            if isinstance(v, str) and v.strip():
                values.append(v.strip())
        if len(set(values)) > 1:
            findings.append(f"{name}: inconsistent values across documents -> {sorted(set(values))[:6]}")
    return findings

def run_vetting(paths: List[str], rules_path: str, settings) -> BatchResult:
    rules = load_rules(rules_path)

    documents: List[DocResult] = []
    findings: List[str] = []

    for path in paths:
        filename = os.path.basename(path)
        raw_text = extract_pdf_text(path, max_chars=settings.max_chars_per_doc)
        send_text = redact(raw_text) if settings.redact_before_sending else raw_text

        try:
            llm_out = llm_classify_and_extract(send_text, filename, rules, settings)
            doc_type = llm_out["doc_type"]
            fields = llm_out["fields"]
        except LLMError as e:
            doc_type = "OTHER"
            fields = {}
            findings.append(f"{filename}: LLM error -> {str(e)[:200]}")

        missing = apply_rules(doc_type, fields, rules)
        doc_decision = "NEEDS_REVIEW" if missing else "NEEDS_REVIEW"  # MVP always needs review per your instruction

        documents.append(DocResult(
            filename=filename,
            doc_type=doc_type,
            fields=fields,
            missing_fields=missing,
            decision=doc_decision
        ))

    findings.extend(apply_cross_doc_checks(documents, rules))

    decision = "NEEDS_REVIEW"
    summary = "Automated vetting completed. Please review flagged items and missing fields."

    report_path = os.path.join("outputs", "atlasza_vetting_report.pdf")
    render_pdf(report_path, decision, summary, findings, documents)

    return BatchResult(
        decision=decision,
        summary=summary,
        findings=findings,
        documents=documents,
        report_path=report_path
    )
# package marker
# AtlasZA Document Vetter (KYC/KYB/AML + Commodities)

Local-first vetting tool to classify and review business compliance and commodity transaction documents:
- KYC (company)
- KYB (company)
- AML Declarations
- Sales Contracts
- Export Permits
- Other supporting PDFs

## What it does
1. Extracts text from PDFs locally
2. (Hybrid mode) Sends redacted text to an external LLM to:
   - classify doc type
   - extract key fields
3. Runs checklist rules + cross-document consistency checks
4. Produces a PDF report with findings

Default outcome: **NEEDS_REVIEW** (MVP behavior).

## Quick start (Mac)
### 1) Create virtual environment
```bash
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
cp .env.example .env
# edit .env and set LLM_API_KEY
streamlit run app.py
 
---

## 5) Run it locally (Mac)
From inside the folder:

```bash
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt

cp .env.example .env
# edit .env and paste your API key

streamlit run app.py
git init
git add .
git commit -m "Initial commit: AtlasZA doc vetter MVP"
git branch -M main
git remote add origin https://github.com/YOUR_USERNAME/atlasza-doc-vetter.git
git push -u origin main
